{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pkl file for mmdet3d framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Set in RadarOCC:\n",
    "{4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 27, 56}\n",
    "\n",
    "Test Set\n",
    "{3, 15, 22, 23, 55}\n",
    "\n",
    "Val SeT\n",
    "{1,2}\n",
    "\n",
    "Adveser weather Set (No reliable GT)\n",
    "{21,46,54}\n",
    "\n",
    "Modify occ_path, sparse_radar_path with your GT/Sparse radar file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "kradar_dict = {}\n",
    "kradar_dict['metadata'] = {'version': 'kradar'}\n",
    "kradar_dict['infos'] = []\n",
    "for seq in [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 27, 56]:\n",
    "\n",
    "    with open('/mnt/Kradar/K-Radar/{}/info_calib/calib_radar_lidar.txt'.format(seq)) as f:\n",
    "                lines = f.readlines()\n",
    "                f.close()\n",
    "    list_calib = list(map(lambda x: float(x), lines[1].split(',')))\n",
    "    frame_difference = int(list_calib[0])\n",
    "    len_occgt = len(glob.glob(\"/mnt/data/DataSet/K-RadarOOC/train/{}/semantic_occupancy_gt_fov/occupancy_gt_with_semantic_fov*.npy\".format(seq)))\n",
    "    len_radar = len(glob.glob(\"/mnt/Kradar/K-Radar/{}/radar_zyx_cube/cube_*.mat\".format(seq)))-frame_difference\n",
    "    seq_size = min(len_occgt,len_radar)\n",
    "\n",
    "    image_files = sorted(glob.glob('/mnt/Kradar/K-Radar/'+str(seq)+'/cam-front/'+ '*.png'))[::3]\n",
    "    seq_size = min(seq_size,len(image_files))\n",
    "    print(seq_size)\n",
    "    for i in range(0,seq_size):\n",
    "        seq_dict = {}\n",
    "        seq_dict['occ_path'] = \"/mnt/data/DataSet/K-RadarOOC/train/{}/semantic_occupancy_gt_fov/occupancy_gt_with_semantic_fov{}.npy\".format(seq,i)\n",
    "        seq_dict['lidar_path'] =\"/mnt/data/DataSet/K-RadarOOC/train/\"+str(seq)+\"/os2-32/os2-32_{0:05d}.bin\".format(i+1)\n",
    "        seq_dict['radar_path'] = \"/mnt/Kradar/K-Radar/\"+str(seq)+\"/radar_zyx_cube/cube_{0:05d}.mat\".format(i+1+frame_difference)\n",
    "        seq_dict['radar_tensor_path'] = \"/mnt/Kradar/K-Radar/\"+str(seq)+\"/radar_tesseract/tesseract_{0:05d}.mat\".format(i+1+frame_difference)\n",
    "        seq_dict['radar_polar_path'] = \"/mnt/18T-Data/kradar/\"+str(seq)+\"/radar_polar_cube/DRAE_{0:05d}.npy\".format(i+1+frame_difference)\n",
    "        seq_dict['sparse_radar_path'] = \"/mnt/18T-Data/kradar/\"+str(seq)+\"/radar_tensor_8doppler/EAsparse_{0:05d}.npz\".format(i+1+frame_difference)\n",
    "        seq_dict['scene_token'] = seq\n",
    "        seq_dict['lidar_token'] = i\n",
    "        seq_dict['cams'] = {'CAM_FRONT': {'data_path': image_files[i],\n",
    "'cam_intrinsic': np.array([[567.72077648,   0.        , 628.72078   ],\n",
    "       [  0.        , 577.21369171, 369.30687   ],\n",
    "       [  0.        ,   0.        ,   1.        ]])\n",
    ",\n",
    "\n",
    "                                'lidar2cam': np.array([[ 1.64325268e-04, -9.99390895e-01,  3.48971584e-02, 1.80000000e-01],\n",
    "       [ 6.72339597e-03,  3.48974743e-02,  9.99368282e-01, -1.30000000e-01],\n",
    "       [-9.99977384e-01,  7.04059534e-05,  6.72503525e-03, -3.12250226e-17],\n",
    "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00]]),\n",
    "                                'sensor2lidar_translation': np.array([-1.80000000e-01,  1.30000000e-01,  3.12250226e-17]),\n",
    "                                'sensor2lidar_rotation' : np.array([[ 1.64325268e-04,  6.72339597e-03, -9.99977384e-01],\n",
    "       [-9.99390895e-01,  3.48974743e-02,  7.04059534e-05],\n",
    "       [ 3.48971584e-02,  9.99368282e-01,  6.72503525e-03]])\n",
    "                                        }\n",
    "                            }\n",
    "        seq_dict['lidar2ego_translation'] = [0,0,0]\n",
    "        seq_dict['lidar2ego_rotation'] = [1,0,0,0]\n",
    "        seq_dict['ego2global_translation'] = [0,0,0]\n",
    "        seq_dict['ego2global_rotation'] = [1,0,0,0]\n",
    "        seq_dict['timestamp'] = i * 1e16\n",
    "        seq_dict['prev'] = i - 1\n",
    "        seq_dict['next'] = i + 1\n",
    "        seq_dict['lidarseg'] = None\n",
    "        seq_dict['token'] = seq_dict['lidar_path']\n",
    "        kradar_dict['infos'].append(seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('kradar_dict_train_doppler8.pkl', 'wb') as f:\n",
    "    pickle.dump(kradar_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
